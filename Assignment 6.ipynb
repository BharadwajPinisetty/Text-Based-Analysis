{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1897fee",
   "metadata": {},
   "source": [
    "# Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b3f89",
   "metadata": {},
   "source": [
    "# Text Summarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebcbd0f",
   "metadata": {},
   "source": [
    "# Text 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ad899",
   "metadata": {},
   "source": [
    "#### Importing libraries to reprocess text data, compute similarity metrics between text elements, and construct and analyze graphs to perform text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9026beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a99af5",
   "metadata": {},
   "source": [
    "#### process a paragraph from a text file into individual sentences and then further split them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a407dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich lese gerne und mag Tiere: Wir haben einen Hund, zwei Katzen und im Garten einen Teich mit Goldfischen\n",
      "Ich gehe auch gerne in die Schule, mein Lieblingsfach ist Mathematik\n",
      "Physik und Chemie mag ich nicht so gerne.\n"
     ]
    }
   ],
   "source": [
    "file = open(r\"C:\\Users\\Public\\text 1.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2011ced",
   "metadata": {},
   "source": [
    "#### Prints the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab166c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['Ich', 'lese', 'gerne', 'und', 'mag', 'Tiere:', 'Wir', 'haben', 'einen', 'Hund,', 'zwei', 'Katzen', 'und', 'im', 'Garten', 'einen', 'Teich', 'mit', 'Goldfischen'], ['Ich', 'gehe', 'auch', 'gerne', 'in', 'die', 'Schule,', 'mein', 'Lieblingsfach', 'ist', 'Mathematik'], ['Physik', 'und', 'Chemie', 'mag', 'ich', 'nicht', 'so', 'gerne.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bd577",
   "metadata": {},
   "source": [
    "#### function aims at computing the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0128f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7b09b",
   "metadata": {},
   "source": [
    "#### creates a similarity matrix to store the similarity scores between each pair of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732a8ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.12573892 0.29488391]\n",
      " [0.12573892 0.         0.10660036]\n",
      " [0.29488391 0.10660036 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08247694",
   "metadata": {},
   "source": [
    "#### creates a graph from the similarity matrix and then apply PageRank to compute scores for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809a137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.3914679821602244, 1: 0.23399789355822842, 2: 0.3745341242815466}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550fa6ea",
   "metadata": {},
   "source": [
    "#### ranks the sentences based on their PageRank scores calculated previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06eb7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.3914679821602244, ['Ich', 'lese', 'gerne', 'und', 'mag', 'Tiere:', 'Wir', 'haben', 'einen', 'Hund,', 'zwei', 'Katzen', 'und', 'im', 'Garten', 'einen', 'Teich', 'mit', 'Goldfischen']), (0.3745341242815466, ['Physik', 'und', 'Chemie', 'mag', 'ich', 'nicht', 'so', 'gerne.']), (0.23399789355822842, ['Ich', 'gehe', 'auch', 'gerne', 'in', 'die', 'Schule,', 'mein', 'Lieblingsfach', 'ist', 'Mathematik'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df340933",
   "metadata": {},
   "source": [
    "#### takes user input to determine how many sentences should be in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7288fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=4\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef6fd1",
   "metadata": {},
   "source": [
    "#### prints the summarized text by joining the selected sentences with a period and space in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e47e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Ich lese gerne und mag Tiere: Wir haben einen Hund, zwei Katzen und im Garten einen Teich mit Goldfischen. Physik und Chemie mag ich nicht so gerne.\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b0cbd",
   "metadata": {},
   "source": [
    "# Text 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbeadbf",
   "metadata": {},
   "source": [
    "#### process a paragraph from a text file into individual sentences and then further split them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ab03ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La vie en France est trÃ¨s diffÃ©rente de celle au Canada\n",
      "Ici, il fait toujours chaud\n",
      "Chaque dimanche, nous allons Ã  la magnifique plage de Biarritz et nous achetons des glaces aprÃ¨s avoir nagÃ© dans la mer.Les FranÃ§ais sont trÃ¨s sympathiques et accueillants\n",
      "Nous parlons franÃ§ais lorsque nous sommes dehors, Ã  l'Ã©cole ou au marchÃ©\n",
      "Cependant, nous continuons de parler anglais Ã  la maison, car mes parents ne veulent pas que je perde ma langue natale.\n"
     ]
    }
   ],
   "source": [
    "file = open(r\"C:\\Users\\Public\\text 2.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859ad42",
   "metadata": {},
   "source": [
    "#### Prints the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a80519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['La', 'vie', 'en', 'France', 'est', 'trÃ¨s', 'diffÃ©rente', 'de', 'celle', 'au', 'Canada'], ['Ici,', 'il', 'fait', 'toujours', 'chaud'], ['Chaque', 'dimanche,', 'nous', 'allons', 'Ã\\xa0', 'la', 'magnifique', 'plage', 'de', 'Biarritz', 'et', 'nous', 'achetons', 'des', 'glaces', 'aprÃ¨s', 'avoir', 'nagÃ©', 'dans', 'la', 'mer.Les', 'FranÃ§ais', 'sont', 'trÃ¨s', 'sympathiques', 'et', 'accueillants'], ['Nous', 'parlons', 'franÃ§ais', 'lorsque', 'nous', 'sommes', 'dehors,', 'Ã\\xa0', \"l'Ã©cole\", 'ou', 'au', 'marchÃ©'], ['Cependant,', 'nous', 'continuons', 'de', 'parler', 'anglais', 'Ã\\xa0', 'la', 'maison,', 'car', 'mes', 'parents', 'ne', 'veulent', 'pas', 'que', 'je', 'perde', 'ma', 'langue', 'natale.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81945fb1",
   "metadata": {},
   "source": [
    "#### function aims at computing the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d57f83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe15c01",
   "metadata": {},
   "source": [
    "#### creates a similarity matrix to store the similarity scores between each pair of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb4ab4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.         0.20994555 0.0805823  0.13159034]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.20994555 0.         0.         0.27914526 0.22792115]\n",
      " [0.0805823  0.         0.27914526 0.         0.17496355]\n",
      " [0.13159034 0.         0.22792115 0.17496355 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb968c17",
   "metadata": {},
   "source": [
    "#### creates a graph from the similarity matrix and then apply PageRank to compute scores for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b63bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.1910303813442053, 1: 0.03614457832948221, 2: 0.3053273365543461, 3: 0.23333630494180363, 4: 0.2341613988301626}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5bd0b1",
   "metadata": {},
   "source": [
    "#### ranks the sentences based on their PageRank scores calculated previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec7f1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.3053273365543461, ['Chaque', 'dimanche,', 'nous', 'allons', 'Ã\\xa0', 'la', 'magnifique', 'plage', 'de', 'Biarritz', 'et', 'nous', 'achetons', 'des', 'glaces', 'aprÃ¨s', 'avoir', 'nagÃ©', 'dans', 'la', 'mer.Les', 'FranÃ§ais', 'sont', 'trÃ¨s', 'sympathiques', 'et', 'accueillants']), (0.2341613988301626, ['Cependant,', 'nous', 'continuons', 'de', 'parler', 'anglais', 'Ã\\xa0', 'la', 'maison,', 'car', 'mes', 'parents', 'ne', 'veulent', 'pas', 'que', 'je', 'perde', 'ma', 'langue', 'natale.']), (0.23333630494180363, ['Nous', 'parlons', 'franÃ§ais', 'lorsque', 'nous', 'sommes', 'dehors,', 'Ã\\xa0', \"l'Ã©cole\", 'ou', 'au', 'marchÃ©']), (0.1910303813442053, ['La', 'vie', 'en', 'France', 'est', 'trÃ¨s', 'diffÃ©rente', 'de', 'celle', 'au', 'Canada']), (0.03614457832948221, ['Ici,', 'il', 'fait', 'toujours', 'chaud'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a435bc",
   "metadata": {},
   "source": [
    "#### takes user input to determine how many sentences should be in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b94bab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 4\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=5\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306dcb1",
   "metadata": {},
   "source": [
    "#### prints the summarized text by joining the selected sentences with a period and space in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af2097f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Chaque dimanche, nous allons Ã  la magnifique plage de Biarritz et nous achetons des glaces aprÃ¨s avoir nagÃ© dans la mer.Les FranÃ§ais sont trÃ¨s sympathiques et accueillants. Cependant, nous continuons de parler anglais Ã  la maison, car mes parents ne veulent pas que je perde ma langue natale.. Nous parlons franÃ§ais lorsque nous sommes dehors, Ã  l'Ã©cole ou au marchÃ©. La vie en France est trÃ¨s diffÃ©rente de celle au Canada\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee13bbf",
   "metadata": {},
   "source": [
    "# Text 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c08f7",
   "metadata": {},
   "source": [
    "#### process a paragraph from a text file into individual sentences and then further split them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d324021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si eres deportista y te gusta el agua puedes nadar, si te gusta la nieve puedes esquiar\n",
      "Si no dispones de mucho tiempo puedes correr o ir en bicicleta.Hay quien prefiere quedarse en casa a ver la televisiÃ³n, jugar videojuegos o navegar en Internet\n",
      "Otras actividades para hacer dentro de casa cuando llueve o hace mucho frÃ­o son escuchar tu mÃºsica favorita, leer un buen libro o aprender a tocar un instrumento\n",
      "Puedes aprovechar tu tiempo libre para estudiar.Si el tiempo es bueno, tal vez quieras ir de compras, salir con amigos a divertirse o pasar tiempo con la familia en algÃºn lugar divertido para todos, como un parque de diversiones, el teatro o el cine\n",
      "Aprovechar el tiempo libre es importante para tener una vida feliz.\n"
     ]
    }
   ],
   "source": [
    "file = open(r\"C:\\Users\\Public\\text 3.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210f8d1",
   "metadata": {},
   "source": [
    "#### Prints the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc535653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['Si', 'eres', 'deportista', 'y', 'te', 'gusta', 'el', 'agua', 'puedes', 'nadar,', 'si', 'te', 'gusta', 'la', 'nieve', 'puedes', 'esquiar'], ['Si', 'no', 'dispones', 'de', 'mucho', 'tiempo', 'puedes', 'correr', 'o', 'ir', 'en', 'bicicleta.Hay', 'quien', 'prefiere', 'quedarse', 'en', 'casa', 'a', 'ver', 'la', 'televisiÃ³n,', 'jugar', 'videojuegos', 'o', 'navegar', 'en', 'Internet'], ['Otras', 'actividades', 'para', 'hacer', 'dentro', 'de', 'casa', 'cuando', 'llueve', 'o', 'hace', 'mucho', 'frÃ\\xado', 'son', 'escuchar', 'tu', 'mÃºsica', 'favorita,', 'leer', 'un', 'buen', 'libro', 'o', 'aprender', 'a', 'tocar', 'un', 'instrumento'], ['Puedes', 'aprovechar', 'tu', 'tiempo', 'libre', 'para', 'estudiar.Si', 'el', 'tiempo', 'es', 'bueno,', 'tal', 'vez', 'quieras', 'ir', 'de', 'compras,', 'salir', 'con', 'amigos', 'a', 'divertirse', 'o', 'pasar', 'tiempo', 'con', 'la', 'familia', 'en', 'algÃºn', 'lugar', 'divertido', 'para', 'todos,', 'como', 'un', 'parque', 'de', 'diversiones,', 'el', 'teatro', 'o', 'el', 'cine'], ['Aprovechar', 'el', 'tiempo', 'libre', 'es', 'importante', 'para', 'tener', 'una', 'vida', 'feliz.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6de13",
   "metadata": {},
   "source": [
    "#### function aims at computing the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04484291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056cb810",
   "metadata": {},
   "source": [
    "#### creates a similarity matrix to store the similarity scores between each pair of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc2248df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.16903085 0.         0.15       0.06030227]\n",
      " [0.16903085 0.         0.23904572 0.3380617  0.05096472]\n",
      " [0.         0.23904572 0.         0.26516504 0.05330018]\n",
      " [0.15       0.3380617  0.26516504 0.         0.4145781 ]\n",
      " [0.06030227 0.05096472 0.05330018 0.4145781  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c988d39",
   "metadata": {},
   "source": [
    "#### creates a graph from the similarity matrix and then apply PageRank to compute scores for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd70062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.12082481777487625, 1: 0.2267064935259036, 2: 0.1629122690466176, 3: 0.3208522527187359, 4: 0.16870416693386664}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783a9c1",
   "metadata": {},
   "source": [
    "#### ranks the sentences based on their PageRank scores calculated previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1b92bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.3208522527187359, ['Puedes', 'aprovechar', 'tu', 'tiempo', 'libre', 'para', 'estudiar.Si', 'el', 'tiempo', 'es', 'bueno,', 'tal', 'vez', 'quieras', 'ir', 'de', 'compras,', 'salir', 'con', 'amigos', 'a', 'divertirse', 'o', 'pasar', 'tiempo', 'con', 'la', 'familia', 'en', 'algÃºn', 'lugar', 'divertido', 'para', 'todos,', 'como', 'un', 'parque', 'de', 'diversiones,', 'el', 'teatro', 'o', 'el', 'cine']), (0.2267064935259036, ['Si', 'no', 'dispones', 'de', 'mucho', 'tiempo', 'puedes', 'correr', 'o', 'ir', 'en', 'bicicleta.Hay', 'quien', 'prefiere', 'quedarse', 'en', 'casa', 'a', 'ver', 'la', 'televisiÃ³n,', 'jugar', 'videojuegos', 'o', 'navegar', 'en', 'Internet']), (0.16870416693386664, ['Aprovechar', 'el', 'tiempo', 'libre', 'es', 'importante', 'para', 'tener', 'una', 'vida', 'feliz.']), (0.1629122690466176, ['Otras', 'actividades', 'para', 'hacer', 'dentro', 'de', 'casa', 'cuando', 'llueve', 'o', 'hace', 'mucho', 'frÃ\\xado', 'son', 'escuchar', 'tu', 'mÃºsica', 'favorita,', 'leer', 'un', 'buen', 'libro', 'o', 'aprender', 'a', 'tocar', 'un', 'instrumento']), (0.12082481777487625, ['Si', 'eres', 'deportista', 'y', 'te', 'gusta', 'el', 'agua', 'puedes', 'nadar,', 'si', 'te', 'gusta', 'la', 'nieve', 'puedes', 'esquiar'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316e9be",
   "metadata": {},
   "source": [
    "#### takes user input to determine how many sentences should be in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29fc8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 3\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=3\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04822760",
   "metadata": {},
   "source": [
    "#### prints the summarized text by joining the selected sentences with a period and space in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74baad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Puedes aprovechar tu tiempo libre para estudiar.Si el tiempo es bueno, tal vez quieras ir de compras, salir con amigos a divertirse o pasar tiempo con la familia en algÃºn lugar divertido para todos, como un parque de diversiones, el teatro o el cine. Si no dispones de mucho tiempo puedes correr o ir en bicicleta.Hay quien prefiere quedarse en casa a ver la televisiÃ³n, jugar videojuegos o navegar en Internet. Aprovechar el tiempo libre es importante para tener una vida feliz.\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
